{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of avalanche events for dataviz in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing standard Python libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to see all rows and columns of dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pays</th>\n",
       "      <th>Massif</th>\n",
       "      <th>Sommet/secteur</th>\n",
       "      <th>itinéraire</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date_format</th>\n",
       "      <th>Heure</th>\n",
       "      <th>Description</th>\n",
       "      <th>Décl à distance</th>\n",
       "      <th>Distance décl</th>\n",
       "      <th>Caractéristique</th>\n",
       "      <th>Dénivelé</th>\n",
       "      <th>Origine principale</th>\n",
       "      <th>Origine secondaire</th>\n",
       "      <th>Alti départ</th>\n",
       "      <th>Commentaire zone départ</th>\n",
       "      <th>Epaisseur rupture</th>\n",
       "      <th>Epaisseur max rupture</th>\n",
       "      <th>Longueur rupture</th>\n",
       "      <th>Ecoulement principal</th>\n",
       "      <th>Commentaire type écoulement</th>\n",
       "      <th>Alti arrivée</th>\n",
       "      <th>Commentaire zone arrivée</th>\n",
       "      <th>Qualité neige</th>\n",
       "      <th>Commentaire qualité neige</th>\n",
       "      <th>Commentaire qualité transportée</th>\n",
       "      <th>Risque MF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1557382479001</td>\n",
       "      <td>France</td>\n",
       "      <td>Aiguilles de l'Argentiere/ Sept Laux</td>\n",
       "      <td>col de l'Amiante</td>\n",
       "      <td>Départ de Rieux Claret pour direction du Roche...</td>\n",
       "      <td>E</td>\n",
       "      <td>07/05/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>11:00</td>\n",
       "      <td>Départ provoqué par une skieuse lors de la des...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Skieur rando.  descente</td>\n",
       "      <td>Neige</td>\n",
       "      <td>2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000560</td>\n",
       "      <td>France</td>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>L'Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>18/12/2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>2010-12-18</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Une plaque friable a été déclenchée par un ski...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Plaque friable</td>\n",
       "      <td>200</td>\n",
       "      <td>Skieur hors piste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2150</td>\n",
       "      <td>L'épaisseur de la rupture était de 40 à 80 cm ...</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 - MARQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000693</td>\n",
       "      <td>France</td>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>Brévent</td>\n",
       "      <td>Combe de Charlanon</td>\n",
       "      <td>T</td>\n",
       "      <td>23/01/2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cette plaque décrite comme &amp;quot;monstrueuse&amp;q...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Plaque de fond</td>\n",
       "      <td>0</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dense</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - LIMITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1390063748315</td>\n",
       "      <td>France</td>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>Col de Bérard</td>\n",
       "      <td>Traversée Crochues - Bérard</td>\n",
       "      <td>W</td>\n",
       "      <td>18/01/2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Un petit incident qui remet les pendules à l'h...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Plaque à vent</td>\n",
       "      <td>150</td>\n",
       "      <td>Skieur rando.  montée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>séche dense</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 - MARQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1426167935840</td>\n",
       "      <td>France</td>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>Flégère</td>\n",
       "      <td>Lac Blanc</td>\n",
       "      <td>SE</td>\n",
       "      <td>06/03/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Avalanche probablement partie spontanément. &lt;b...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Plaque à vent</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dense</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sèche dure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 - MARQUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id    Pays                                Massif  \\\n",
       "0  1557382479001  France  Aiguilles de l'Argentiere/ Sept Laux   \n",
       "1       50000560  France                      Aiguilles Rouges   \n",
       "2       50000693  France                      Aiguilles Rouges   \n",
       "3  1390063748315  France                      Aiguilles Rouges   \n",
       "4  1426167935840  France                      Aiguilles Rouges   \n",
       "\n",
       "     Sommet/secteur                                         itinéraire  \\\n",
       "0  col de l'Amiante  Départ de Rieux Claret pour direction du Roche...   \n",
       "1           L'Index                                                NaN   \n",
       "2           Brévent                                 Combe de Charlanon   \n",
       "3     Col de Bérard                        Traversée Crochues - Bérard   \n",
       "4           Flégère                                          Lac Blanc   \n",
       "\n",
       "  Orientation        Date  year  month  day date_format     Heure  \\\n",
       "0           E  07/05/2019  2019      5    7  2019-05-07     11:00   \n",
       "1          SE  18/12/2010  2010     12   18  2010-12-18  13:00:00   \n",
       "2           T  23/01/2012  2012      1   23  2012-01-23       NaN   \n",
       "3           W  18/01/2014  2014      1   18  2014-01-18       NaN   \n",
       "4          SE  06/03/2015  2015      3    6  2015-03-06       NaN   \n",
       "\n",
       "                                         Description  Décl à distance  \\\n",
       "0  Départ provoqué par une skieuse lors de la des...            False   \n",
       "1  Une plaque friable a été déclenchée par un ski...            False   \n",
       "2  Cette plaque décrite comme &quot;monstrueuse&q...            False   \n",
       "3  Un petit incident qui remet les pendules à l'h...            False   \n",
       "4  Avalanche probablement partie spontanément. <b...            False   \n",
       "\n",
       "   Distance décl Caractéristique  Dénivelé       Origine principale  \\\n",
       "0              0             NaN         0  Skieur rando.  descente   \n",
       "1              0  Plaque friable       200        Skieur hors piste   \n",
       "2              0  Plaque de fond         0                 Inconnue   \n",
       "3              0   Plaque à vent       150    Skieur rando.  montée   \n",
       "4              0   Plaque à vent         0                      NaN   \n",
       "\n",
       "  Origine secondaire  Alti départ  \\\n",
       "0              Neige         2750   \n",
       "1                NaN         2150   \n",
       "2                NaN         2000   \n",
       "3                NaN         2400   \n",
       "4                NaN         2280   \n",
       "\n",
       "                             Commentaire zone départ  Epaisseur rupture  \\\n",
       "0                                                NaN                  0   \n",
       "1  L'épaisseur de la rupture était de 40 à 80 cm ...                 40   \n",
       "2                                                NaN                  0   \n",
       "3                                                NaN                  0   \n",
       "4                                                NaN                  0   \n",
       "\n",
       "   Epaisseur max rupture  Longueur rupture Ecoulement principal  \\\n",
       "0                     50                 0                  NaN   \n",
       "1                     80                20                  NaN   \n",
       "2                      0                 0                Dense   \n",
       "3                      0                 0                  NaN   \n",
       "4                      0                 0                Dense   \n",
       "\n",
       "  Commentaire type écoulement  Alti arrivée Commentaire zone arrivée  \\\n",
       "0                         NaN          2700                      NaN   \n",
       "1                         NaN          1950                      NaN   \n",
       "2                         NaN             0                      NaN   \n",
       "3                         NaN             0                      NaN   \n",
       "4                         NaN             0                      NaN   \n",
       "\n",
       "  Qualité neige Commentaire qualité neige Commentaire qualité transportée  \\\n",
       "0           NaN                       NaN                             NaN   \n",
       "1           NaN                       NaN                             NaN   \n",
       "2           NaN                       NaN                             NaN   \n",
       "3           NaN               séche dense                             NaN   \n",
       "4    Sèche dure                       NaN                             NaN   \n",
       "\n",
       "    Risque MF  \n",
       "0     Inconnu  \n",
       "1  3 - MARQUE  \n",
       "2  2 - LIMITE  \n",
       "3  3 - MARQUE  \n",
       "4  3 - MARQUE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking our dataset\n",
    "df_aval = pd.read_excel(\"aval_alps_2010_2019_org.xlsx\")\n",
    "df_aval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167 entries, 0 to 1166\n",
      "Data columns (total 32 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   Id                               1167 non-null   int64         \n",
      " 1   Pays                             1167 non-null   object        \n",
      " 2   Massif                           1167 non-null   object        \n",
      " 3   Sommet/secteur                   1122 non-null   object        \n",
      " 4   itinéraire                       904 non-null    object        \n",
      " 5   Orientation                      1167 non-null   object        \n",
      " 6   Date                             1167 non-null   object        \n",
      " 7   year                             1167 non-null   int64         \n",
      " 8   month                            1167 non-null   int64         \n",
      " 9   day                              1167 non-null   int64         \n",
      " 10  date_format                      1167 non-null   datetime64[ns]\n",
      " 11  Heure                            652 non-null    object        \n",
      " 12  Description                      1164 non-null   object        \n",
      " 13  Décl à distance                  1167 non-null   bool          \n",
      " 14  Distance décl                    1167 non-null   int64         \n",
      " 15  Caractéristique                  402 non-null    object        \n",
      " 16  Dénivelé                         1167 non-null   int64         \n",
      " 17  Origine principale               902 non-null    object        \n",
      " 18  Origine secondaire               161 non-null    object        \n",
      " 19  Alti départ                      1167 non-null   int64         \n",
      " 20  Commentaire zone départ          99 non-null     object        \n",
      " 21  Epaisseur rupture                1167 non-null   int64         \n",
      " 22  Epaisseur max rupture            1167 non-null   int64         \n",
      " 23  Longueur rupture                 1167 non-null   int64         \n",
      " 24  Ecoulement principal             528 non-null    object        \n",
      " 25  Commentaire type écoulement      20 non-null     object        \n",
      " 26  Alti arrivée                     1167 non-null   int64         \n",
      " 27  Commentaire zone arrivée         89 non-null     object        \n",
      " 28  Qualité neige                    429 non-null    object        \n",
      " 29  Commentaire qualité neige        66 non-null     object        \n",
      " 30  Commentaire qualité transportée  7 non-null      object        \n",
      " 31  Risque MF                        1167 non-null   object        \n",
      "dtypes: bool(1), datetime64[ns](1), int64(11), object(19)\n",
      "memory usage: 283.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# deeper look on all variables\n",
    "df_aval.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France    1167\n",
       "Name: Pays, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing values of variable\n",
    "df_aval.Pays.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Pays', 'Massif', 'Sommet/secteur', 'itinéraire', 'Orientation',\n",
       "       'Date', 'year', 'month', 'day', 'date_format', 'Heure', 'Description',\n",
       "       'Décl à distance', 'Distance décl', 'Caractéristique', 'Dénivelé',\n",
       "       'Origine principale', 'Origine secondaire', 'Alti départ',\n",
       "       'Commentaire zone départ', 'Epaisseur rupture', 'Epaisseur max rupture',\n",
       "       'Longueur rupture', 'Ecoulement principal',\n",
       "       'Commentaire type écoulement', 'Alti arrivée',\n",
       "       'Commentaire zone arrivée', 'Qualité neige',\n",
       "       'Commentaire qualité neige', 'Commentaire qualité transportée',\n",
       "       'Risque MF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing names of columns for easier copypaste later\n",
    "df_aval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plaque de fond        135\n",
       "Plaque à vent         122\n",
       "Plaque friable        108\n",
       "Départ ponctuel        21\n",
       "Plaque dure             8\n",
       "Plaque sur glacier      7\n",
       "Sur-avalanche           1\n",
       "Name: Caractéristique, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Caractéristique\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding variable to English\n",
    "df_aval[\"Caractéristique\"] = df_aval[\"Caractéristique\"].apply(lambda x: \n",
    "                                     \"bottom layer\" if x == \"Plaque de fond\"\n",
    "                                     else \"windy slope\" if x == \"Plaque à vent\"\n",
    "                                     else \"fragile layer\" if x == \"Plaque friable\"\n",
    "                                    else \"one-off event\" if x == \"Départ ponctuel\"\n",
    "                                    else \"hard layer\" if x == \"Plaque dure\"\n",
    "                                     else \"glacial layer\" if x == \"Plaque sur glacier\"\n",
    "                                      else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1082\n",
       "True       85\n",
       "Name: Décl à distance, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Décl à distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       863\n",
       "50       35\n",
       "100      34\n",
       "30       32\n",
       "150      25\n",
       "80       22\n",
       "20       20\n",
       "200      17\n",
       "300      16\n",
       "40       15\n",
       "70       13\n",
       "10       10\n",
       "60       10\n",
       "250       7\n",
       "25        7\n",
       "35        6\n",
       "15        5\n",
       "500       4\n",
       "400       3\n",
       "120       3\n",
       "350       2\n",
       "1500      2\n",
       "5         2\n",
       "8         1\n",
       "4         1\n",
       "2         1\n",
       "2000      1\n",
       "45        1\n",
       "75        1\n",
       "125       1\n",
       "160       1\n",
       "180       1\n",
       "450       1\n",
       "700       1\n",
       "800       1\n",
       "1400      1\n",
       "90        1\n",
       "Name: Longueur rupture, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Longueur rupture\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sèche poudreuse    204\n",
       "Humide             152\n",
       "Sèche dure          34\n",
       "Mouillée            31\n",
       "Aucun                8\n",
       "Name: Qualité neige, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Qualité neige\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding variable to English\n",
    "df_aval[\"Qualité neige\"] = df_aval[\"Qualité neige\"].apply(lambda x: \n",
    "                                     \"dry powder-like snow\" if x == \"Sèche poudreuse\"\n",
    "                                     else \"humid snow\" if x == \"Humide\"\n",
    "                                     else \"hard dry snow\" if x == \"Sèche dure\"\n",
    "                                    else \"wet snow\" if x == \"Mouillée\"\n",
    "                                     else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1005\n",
       "200       23\n",
       "100       21\n",
       "300       17\n",
       "150       12\n",
       "500        8\n",
       "400        7\n",
       "120        6\n",
       "350        6\n",
       "250        5\n",
       "80         4\n",
       "40         3\n",
       "50         3\n",
       "60         3\n",
       "110        3\n",
       "1200       2\n",
       "130        2\n",
       "20         2\n",
       "800        2\n",
       "450        2\n",
       "70         2\n",
       "600        2\n",
       "700        2\n",
       "30         2\n",
       "550        2\n",
       "25         1\n",
       "90         1\n",
       "10         1\n",
       "170        1\n",
       "1400       1\n",
       "180        1\n",
       "220        1\n",
       "230        1\n",
       "1260       1\n",
       "310        1\n",
       "320        1\n",
       "390        1\n",
       "570        1\n",
       "580        1\n",
       "620        1\n",
       "650        1\n",
       "710        1\n",
       "750        1\n",
       "1000       1\n",
       "1100       1\n",
       "270        1\n",
       "Name: Dénivelé, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Dénivelé\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Réchauffement                      166\n",
       "Skieur rando.  descente            159\n",
       "Skieur hors piste                  133\n",
       "Neige                              108\n",
       "Skieur rando.  montée               98\n",
       "Inconnue                            47\n",
       "Surfeur                             25\n",
       "GAZEX                               23\n",
       "Vent                                21\n",
       "Grenadage hélico                    20\n",
       "Grenadage à main                    19\n",
       "Pluie                               15\n",
       "Alpiniste                           13\n",
       "Minage de corniche                  10\n",
       "Piéton                              10\n",
       "Engin de damage                      6\n",
       "CATEX                                6\n",
       "Raquettiste                          5\n",
       "Autres                               5\n",
       "Chute de sérac                       5\n",
       "Autre avalanche                      2\n",
       "Engin de déneigement                 2\n",
       "Avalancheur                          2\n",
       "Speed riding                         1\n",
       "Déclenchement de corniche à ski      1\n",
       "Name: Origine principale, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Origine principale\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding variable to English\n",
    "df_aval[\"Origine principale\"] = df_aval[\"Origine principale\"].apply(lambda x: \n",
    "                                    \"ski alpinisme-downhill\" if x == \"Skieur rando.  descente\"\n",
    "                                    else \"ski alpinisme-uphill\" if x == \"Skieur rando.  montée\"\n",
    "                                    else \"ski outside of piste\" if x == \"Skieur hors piste\"\n",
    "                                    else \"unknown\" if x == \"Inconnue\"\n",
    "                                    else \"snowboard\" if x == \"Surfeur\"\n",
    "                                    else \"avalanche control system (GATEX)\" if x == \"GAZEX\"\n",
    "                                    else \"bombing from helicopter\" if x == \"Grenadage hélico\"\n",
    "                                    else \"tossing explosives manually\" if x == \"Grenadage à main\"\n",
    "                                    else \"alpiniste\" if x == \"Alpiniste\"\n",
    "                                    else \"hiking\" if x == \"Piéton\"\n",
    "                                    else \"mining\" if x == \"Minage de corniche\"\n",
    "                                    else \"snowshoes trip\" if x == \"Raquettiste\"\n",
    "                                    else \"fall of block of glacial ice\" if x == \"Chute de sérac\"\n",
    "                                    else \"snowshoes trip\" if x == \"Raquettiste\"\n",
    "                                    else \"CATEX blasting (cable carrying explosives)\" if x == \"CATEX\"\n",
    "                                    else \"wind\" if x == \"Vent\"\n",
    "                                    else \"snow grooming\" if x == \"Engin de damage\"\n",
    "                                    else \"snow grooming\" if x == \"Engin de déneigement\"\n",
    "                                    else \"rain\" if x == \"Pluie\"\n",
    "                                     else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neige                    67\n",
       "Réchauffement            45\n",
       "Vent                     40\n",
       "Pluie                     7\n",
       "Raquettiste               1\n",
       "Skieur rando.  montée     1\n",
       "Name: Origine secondaire, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Origine secondaire\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding variable to English\n",
    "df_aval[\"Origine secondaire\"] = df_aval[\"Origine secondaire\"].apply(lambda x: \n",
    "                                     \"snow\" if x == \"Neige\"\n",
    "                                     else \"warming\" if x == \"Réchauffement\"\n",
    "                                     else \"wind\" if x == \"Vent\"\n",
    "                                    else \"rain\" if x == \"Pluie\"\n",
    "                                     else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        244\n",
       "2300      47\n",
       "2200      42\n",
       "2400      42\n",
       "2600      39\n",
       "2700      39\n",
       "2500      32\n",
       "2000      31\n",
       "2900      28\n",
       "2650      26\n",
       "3000      26\n",
       "2450      25\n",
       "2750      25\n",
       "2350      21\n",
       "2550      20\n",
       "2800      20\n",
       "2100      18\n",
       "2050      16\n",
       "2150      15\n",
       "2250      14\n",
       "1900      12\n",
       "1850      11\n",
       "2950      10\n",
       "1950      10\n",
       "3100       9\n",
       "3350       9\n",
       "1800       9\n",
       "3200       8\n",
       "2480       7\n",
       "3600       7\n",
       "1700       7\n",
       "2420       6\n",
       "2320       6\n",
       "2850       6\n",
       "2170       6\n",
       "2280       6\n",
       "3250       5\n",
       "2460       5\n",
       "2380       5\n",
       "3300       5\n",
       "2620       5\n",
       "2670       5\n",
       "1750       5\n",
       "3020       5\n",
       "3550       5\n",
       "1930       4\n",
       "3050       4\n",
       "2370       4\n",
       "2680       4\n",
       "2660       4\n",
       "2080       4\n",
       "2520       4\n",
       "3400       4\n",
       "2330       4\n",
       "3500       3\n",
       "2635       3\n",
       "2390       3\n",
       "2290       3\n",
       "1940       3\n",
       "3030       3\n",
       "2470       3\n",
       "1600       3\n",
       "1690       3\n",
       "2360       3\n",
       "2530       3\n",
       "2510       3\n",
       "2560       3\n",
       "2580       2\n",
       "2130       2\n",
       "2570       2\n",
       "2030       2\n",
       "1650       2\n",
       "2770       2\n",
       "2760       2\n",
       "1820       2\n",
       "2175       2\n",
       "2440       2\n",
       "1830       2\n",
       "2690       2\n",
       "2475       2\n",
       "1980       2\n",
       "1720       2\n",
       "2270       2\n",
       "1920       2\n",
       "3080       2\n",
       "2340       2\n",
       "1400       2\n",
       "3275       2\n",
       "3180       2\n",
       "3150       2\n",
       "3497       2\n",
       "2875       2\n",
       "2225       2\n",
       "1870       2\n",
       "1550       2\n",
       "2890       2\n",
       "2210       2\n",
       "2110       2\n",
       "2120       2\n",
       "2920       2\n",
       "2343       1\n",
       "2310       1\n",
       "2265       1\n",
       "250        1\n",
       "2260       1\n",
       "2540       1\n",
       "2515       1\n",
       "2068       1\n",
       "2070       1\n",
       "2490       1\n",
       "2160       1\n",
       "2220       1\n",
       "2416       1\n",
       "2180       1\n",
       "2195       1\n",
       "2323       1\n",
       "2240       1\n",
       "2090       1\n",
       "2185       1\n",
       "2190       1\n",
       "2430       1\n",
       "2205       1\n",
       "2040       1\n",
       "2590       1\n",
       "1730       1\n",
       "3442       1\n",
       "3450       1\n",
       "3460       1\n",
       "3520       1\n",
       "1500       1\n",
       "1520       1\n",
       "1555       1\n",
       "3630       1\n",
       "3650       1\n",
       "1638       1\n",
       "1675       1\n",
       "1680       1\n",
       "1770       1\n",
       "3430       1\n",
       "1780       1\n",
       "1790       1\n",
       "1825       1\n",
       "1880       1\n",
       "3950       1\n",
       "1915       1\n",
       "24450      1\n",
       "1960       1\n",
       "1965       1\n",
       "4020       1\n",
       "2020       1\n",
       "2025       1\n",
       "3440       1\n",
       "3376       1\n",
       "2595       1\n",
       "2820       1\n",
       "2610       1\n",
       "2615       1\n",
       "2630       1\n",
       "4700       1\n",
       "17000      1\n",
       "2683       1\n",
       "2710       1\n",
       "2715       1\n",
       "2720       1\n",
       "2730       1\n",
       "2740       1\n",
       "2780       1\n",
       "2840       1\n",
       "3340       1\n",
       "2845       1\n",
       "2860       1\n",
       "2870       1\n",
       "2880       1\n",
       "2930       1\n",
       "3007       1\n",
       "3040       1\n",
       "1020       1\n",
       "3120       1\n",
       "3130       1\n",
       "3170       1\n",
       "3240       1\n",
       "2790       1\n",
       "Name: Alti départ, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Alti départ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      852\n",
       "30      52\n",
       "50      43\n",
       "100     41\n",
       "20      39\n",
       "40      35\n",
       "80      23\n",
       "60      17\n",
       "150     12\n",
       "10      10\n",
       "200      8\n",
       "70       7\n",
       "25       5\n",
       "15       5\n",
       "130      4\n",
       "120      2\n",
       "300      2\n",
       "250      2\n",
       "5        2\n",
       "2        2\n",
       "90       1\n",
       "140      1\n",
       "12       1\n",
       "500      1\n",
       "Name: Epaisseur rupture, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Epaisseur rupture\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense      426\n",
       "Mixte       83\n",
       "Aérosol     19\n",
       "Name: Ecoulement principal, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval[\"Ecoulement principal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding variable to English\n",
    "df_aval[\"Ecoulement principal\"] = df_aval[\"Ecoulement principal\"].apply(lambda x: \n",
    "                                     \"dense\" if x == \"Dense\"\n",
    "                                     else \"mixed\" if x == \"Mixte\"\n",
    "                                     else \"aerosol\" if x == \"Aérosol\"\n",
    "                                     else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of not needed data for visualization\n",
    "df_aval = df_aval.drop(columns=['Pays', 'Id', 'Commentaire qualité transportée', \n",
    "                                 'Commentaire type écoulement', 'Commentaire qualité neige',\n",
    "                                'Commentaire zone arrivée', 'Commentaire zone départ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Massif', 'Sommet/secteur', 'itinéraire', 'Orientation', 'Date', 'year',\n",
       "       'month', 'day', 'date_format', 'Heure', 'Description',\n",
       "       'Décl à distance', 'Distance décl', 'Caractéristique', 'Dénivelé',\n",
       "       'Origine principale', 'Origine secondaire', 'Alti départ',\n",
       "       'Epaisseur rupture', 'Epaisseur max rupture', 'Longueur rupture',\n",
       "       'Ecoulement principal', 'Alti arrivée', 'Qualité neige', 'Risque MF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing names of columns\n",
    "df_aval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming variables to English\n",
    "df_aval.columns = ['massif', 'mountain/area', 'plan_of_trip', 'orientation', 'date', 'year',\n",
    "       'month', 'day', 'date_format', 'hour', 'description',\n",
    "       'remote_avalanche_triggering', 'distance_of_remote_trigger', 'characteristics', 'elevation_gain',\n",
    "       'main_cause_of_avalanche', 'secondary_cause_of_avalanche', 'altitude_of_depart',\n",
    "       'thickness_of_avalanche_breakdown', 'max_thickness_of_avalanche_breakdown', 'length_of_avalanche_breakdown',\n",
    "       'main_snowflow', 'altitude_of_arrival', 'snow_quality', 'risque_mf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>massif</th>\n",
       "      <th>mountain/area</th>\n",
       "      <th>plan_of_trip</th>\n",
       "      <th>orientation</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date_format</th>\n",
       "      <th>hour</th>\n",
       "      <th>description</th>\n",
       "      <th>remote_avalanche_triggering</th>\n",
       "      <th>distance_of_remote_trigger</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>elevation_gain</th>\n",
       "      <th>main_cause_of_avalanche</th>\n",
       "      <th>secondary_cause_of_avalanche</th>\n",
       "      <th>altitude_of_depart</th>\n",
       "      <th>thickness_of_avalanche_breakdown</th>\n",
       "      <th>max_thickness_of_avalanche_breakdown</th>\n",
       "      <th>length_of_avalanche_breakdown</th>\n",
       "      <th>main_snowflow</th>\n",
       "      <th>altitude_of_arrival</th>\n",
       "      <th>snow_quality</th>\n",
       "      <th>risque_mf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aiguilles de l'Argentiere/ Sept Laux</td>\n",
       "      <td>col de l'Amiante</td>\n",
       "      <td>Départ de Rieux Claret pour direction du Roche...</td>\n",
       "      <td>E</td>\n",
       "      <td>07/05/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>11:00</td>\n",
       "      <td>Départ provoqué par une skieuse lors de la des...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>ski alpinisme-downhill</td>\n",
       "      <td>snow</td>\n",
       "      <td>2750</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>L'Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>18/12/2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>2010-12-18</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Une plaque friable a été déclenchée par un ski...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>fragile layer</td>\n",
       "      <td>200</td>\n",
       "      <td>ski outside of piste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2150</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 - MARQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>Brévent</td>\n",
       "      <td>Combe de Charlanon</td>\n",
       "      <td>T</td>\n",
       "      <td>23/01/2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cette plaque décrite comme &amp;quot;monstrueuse&amp;q...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>bottom layer</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dense</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - LIMITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>Col de Bérard</td>\n",
       "      <td>Traversée Crochues - Bérard</td>\n",
       "      <td>W</td>\n",
       "      <td>18/01/2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Un petit incident qui remet les pendules à l'h...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>windy slope</td>\n",
       "      <td>150</td>\n",
       "      <td>ski alpinisme-uphill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 - MARQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aiguilles Rouges</td>\n",
       "      <td>Flégère</td>\n",
       "      <td>Lac Blanc</td>\n",
       "      <td>SE</td>\n",
       "      <td>06/03/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Avalanche probablement partie spontanément. &lt;b...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>windy slope</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dense</td>\n",
       "      <td>0</td>\n",
       "      <td>hard dry snow</td>\n",
       "      <td>3 - MARQUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 massif     mountain/area  \\\n",
       "0  Aiguilles de l'Argentiere/ Sept Laux  col de l'Amiante   \n",
       "1                      Aiguilles Rouges           L'Index   \n",
       "2                      Aiguilles Rouges           Brévent   \n",
       "3                      Aiguilles Rouges     Col de Bérard   \n",
       "4                      Aiguilles Rouges           Flégère   \n",
       "\n",
       "                                        plan_of_trip orientation        date  \\\n",
       "0  Départ de Rieux Claret pour direction du Roche...           E  07/05/2019   \n",
       "1                                                NaN          SE  18/12/2010   \n",
       "2                                 Combe de Charlanon           T  23/01/2012   \n",
       "3                        Traversée Crochues - Bérard           W  18/01/2014   \n",
       "4                                          Lac Blanc          SE  06/03/2015   \n",
       "\n",
       "   year  month  day date_format      hour  \\\n",
       "0  2019      5    7  2019-05-07     11:00   \n",
       "1  2010     12   18  2010-12-18  13:00:00   \n",
       "2  2012      1   23  2012-01-23       NaN   \n",
       "3  2014      1   18  2014-01-18       NaN   \n",
       "4  2015      3    6  2015-03-06       NaN   \n",
       "\n",
       "                                         description  \\\n",
       "0  Départ provoqué par une skieuse lors de la des...   \n",
       "1  Une plaque friable a été déclenchée par un ski...   \n",
       "2  Cette plaque décrite comme &quot;monstrueuse&q...   \n",
       "3  Un petit incident qui remet les pendules à l'h...   \n",
       "4  Avalanche probablement partie spontanément. <b...   \n",
       "\n",
       "   remote_avalanche_triggering  distance_of_remote_trigger characteristics  \\\n",
       "0                        False                           0             NaN   \n",
       "1                        False                           0   fragile layer   \n",
       "2                        False                           0    bottom layer   \n",
       "3                        False                           0     windy slope   \n",
       "4                        False                           0     windy slope   \n",
       "\n",
       "   elevation_gain main_cause_of_avalanche secondary_cause_of_avalanche  \\\n",
       "0               0  ski alpinisme-downhill                         snow   \n",
       "1             200    ski outside of piste                          NaN   \n",
       "2               0                 unknown                          NaN   \n",
       "3             150    ski alpinisme-uphill                          NaN   \n",
       "4               0                     NaN                          NaN   \n",
       "\n",
       "   altitude_of_depart  thickness_of_avalanche_breakdown  \\\n",
       "0                2750                                 0   \n",
       "1                2150                                40   \n",
       "2                2000                                 0   \n",
       "3                2400                                 0   \n",
       "4                2280                                 0   \n",
       "\n",
       "   max_thickness_of_avalanche_breakdown  length_of_avalanche_breakdown  \\\n",
       "0                                    50                              0   \n",
       "1                                    80                             20   \n",
       "2                                     0                              0   \n",
       "3                                     0                              0   \n",
       "4                                     0                              0   \n",
       "\n",
       "  main_snowflow  altitude_of_arrival   snow_quality   risque_mf  \n",
       "0           NaN                 2700            NaN     Inconnu  \n",
       "1           NaN                 1950            NaN  3 - MARQUE  \n",
       "2         dense                    0            NaN  2 - LIMITE  \n",
       "3           NaN                    0            NaN  3 - MARQUE  \n",
       "4         dense                    0  hard dry snow  3 - MARQUE  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the result\n",
    "df_aval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12:00                              41\n",
       "11:00                              36\n",
       "14:00                              32\n",
       "12:30                              29\n",
       "15:00                              26\n",
       "13:30                              22\n",
       "16:00                              20\n",
       "13:00                              19\n",
       "10:30                              19\n",
       "11:30                              18\n",
       "10:00                              16\n",
       "09:00                              12\n",
       "13:00:00                            9\n",
       "14:30                               9\n",
       "17:30                               9\n",
       "15:30                               9\n",
       "08:00                               8\n",
       "10:30:00                            7\n",
       "08:30                               7\n",
       "17:00                               6\n",
       "10:15                               6\n",
       "15:00:00                            6\n",
       "12:00:00                            6\n",
       "18:00                               5\n",
       "11:00:00                            5\n",
       "14:45                               5\n",
       "16:30                               5\n",
       "15:45                               5\n",
       "14:00:00                            5\n",
       "15:30:00                            4\n",
       "11:45                               4\n",
       "10:45                               4\n",
       "16:00:00                            4\n",
       "11h30                               4\n",
       "14:40                               3\n",
       "13:45                               3\n",
       "15:50                               3\n",
       "14:25                               3\n",
       "12:15:00                            3\n",
       "10:00:00                            3\n",
       "14:15                               3\n",
       "17:00:00                            3\n",
       "11:10:00                            3\n",
       "20:00                               3\n",
       "06:00                               3\n",
       "09:30                               3\n",
       "13:30:00                            3\n",
       "11:15                               3\n",
       "17:30:00                            2\n",
       "13:40                               2\n",
       "14:15:00                            2\n",
       "04:00                               2\n",
       "11:40                               2\n",
       "11:30:00                            2\n",
       "15:25                               2\n",
       "16:15                               2\n",
       "08:15                               2\n",
       "07:40                               2\n",
       "13:50                               2\n",
       "09:30:00                            2\n",
       "15:20:00                            2\n",
       "16:30:00                            2\n",
       "16:35                               2\n",
       "09:15                               2\n",
       "16:45                               2\n",
       "10.00                               2\n",
       "18:00:00                            2\n",
       "12:10                               2\n",
       "11:15:00                            2\n",
       "11h45                               2\n",
       "12:45                               2\n",
       "14:10                               2\n",
       "19:00                               2\n",
       "12:50                               2\n",
       "11:45:00                            2\n",
       "09:00:00                            2\n",
       "13:15                               2\n",
       "17:45                               1\n",
       "14:25:00                            1\n",
       "9:30                                1\n",
       "12h45                               1\n",
       "11:40:00                            1\n",
       "09:45:00                            1\n",
       "06:30                               1\n",
       "10h                                 1\n",
       "13h00                               1\n",
       "04:30                               1\n",
       "17:15                               1\n",
       "07:20                               1\n",
       "14h50                               1\n",
       "12:30:00                            1\n",
       "10:34                               1\n",
       "11                                  1\n",
       "16:10:00                            1\n",
       "14:40:00                            1\n",
       "13:10:00                            1\n",
       "9:00                                1\n",
       "11:55                               1\n",
       "13:40:00                            1\n",
       "14h30                               1\n",
       "08:00:00                            1\n",
       "07:30                               1\n",
       "18:30:00                            1\n",
       "13h00                               1\n",
       "13:45:00                            1\n",
       "15:10:00                            1\n",
       "12:20                               1\n",
       "17:20                               1\n",
       "08:30:00                            1\n",
       "09:24                               1\n",
       "13:20                               1\n",
       "08h30                               1\n",
       "08:45:00                            1\n",
       "13:05                               1\n",
       "15h30                               1\n",
       "14:20:00                            1\n",
       "00:15:00                            1\n",
       "10:25:00                            1\n",
       "16:50                               1\n",
       "18:01                               1\n",
       "12h00                               1\n",
       "Début d'après-midi probablement     1\n",
       "05:15                               1\n",
       "17:05                               1\n",
       "14h45                               1\n",
       "11;00                               1\n",
       "11:10                               1\n",
       "11h                                 1\n",
       "01:00                               1\n",
       "08:15:00                            1\n",
       "1300                                1\n",
       "12:15                               1\n",
       "8 h                                 1\n",
       "14h 30                              1\n",
       "09:06                               1\n",
       "?                                   1\n",
       "10:40                               1\n",
       "11:05                               1\n",
       "6:00                                1\n",
       "12:0                                1\n",
       "05:40                               1\n",
       "10:50                               1\n",
       "11:13                               1\n",
       "18:40                               1\n",
       "08:0                                1\n",
       "15:40                               1\n",
       "8:30                                1\n",
       "09:50:00                            1\n",
       "11.00                               1\n",
       "11H30                               1\n",
       "15:26                               1\n",
       "08:50:00                            1\n",
       "10:20:00                            1\n",
       "13:10                               1\n",
       "10:10                               1\n",
       "21:00                               1\n",
       "8:00                                1\n",
       "11H                                 1\n",
       "10h58                               1\n",
       "13h30                               1\n",
       "16:10                               1\n",
       "11:32                               1\n",
       "Inconnue                            1\n",
       "14:52                               1\n",
       "12:06                               1\n",
       "17 h 30                             1\n",
       "12h30                               1\n",
       "13:20:00                            1\n",
       "08/45                               1\n",
       "12/14                               1\n",
       "15:20                               1\n",
       "13:15:00                            1\n",
       "14h à 15h                           1\n",
       "Avant 10h                           1\n",
       "16:20:00                            1\n",
       "22:00:00                            1\n",
       "9h30                                1\n",
       "10:05                               1\n",
       "09h                                 1\n",
       "10:15:00                            1\n",
       "14h43                               1\n",
       "14:05:00                            1\n",
       "10:20                               1\n",
       "17:50                               1\n",
       "12:40                               1\n",
       "10:39                               1\n",
       "00:00:00                            1\n",
       "11h00                               1\n",
       "14:30:00                            1\n",
       "14:11                               1\n",
       "16:40                               1\n",
       "16:40:00                            1\n",
       "14:20                               1\n",
       "14H39                               1\n",
       "11:07                               1\n",
       "15h                                 1\n",
       "13:35:00                            1\n",
       "9                                   1\n",
       "09:25                               1\n",
       "06:20                               1\n",
       "03:00                               1\n",
       "15:15                               1\n",
       "19:00:00                            1\n",
       "16:15:00                            1\n",
       "02:08                               1\n",
       "11:25                               1\n",
       "05:00                               1\n",
       "Name: hour, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing different values for hour\n",
    "df_aval.hour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting leading and trailing spaces \n",
    "df_aval.hour = df_aval.hour.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unifying different writing of same time expressions\n",
    "df_aval['hour'].replace(['h', 'H', '/', ';'], ':', inplace=True, regex=True)\n",
    "df_aval['hour'].replace([' : ', ':  '], ':', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only hours and minutes\n",
    "df_aval.hour = df_aval[\"hour\"].str[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing spaces inside the values\n",
    "df_aval.hour = df_aval.hour.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling shorter values with 0 to have unified length of value to 5 chars\n",
    "df_aval.hour = df_aval[\"hour\"].str.ljust(5, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12:00    49\n",
       "11:00    45\n",
       "14:00    37\n",
       "15:00    33\n",
       "12:30    31\n",
       "13:00    30\n",
       "13:30    26\n",
       "10:30    26\n",
       "11:30    25\n",
       "16:00    24\n",
       "10:00    20\n",
       "09:00    15\n",
       "15:30    14\n",
       "14:30    12\n",
       "17:30    12\n",
       "08:00    10\n",
       "08:30     9\n",
       "17:00     9\n",
       "11:45     8\n",
       "10:15     7\n",
       "18:00     7\n",
       "16:30     7\n",
       "14:45     6\n",
       "09:30     5\n",
       "14:15     5\n",
       "15:45     5\n",
       "11:15     5\n",
       "12:15     4\n",
       "14:25     4\n",
       "13:45     4\n",
       "14:40     4\n",
       "10:45     4\n",
       "11:10     4\n",
       "13:40     3\n",
       "19:00     3\n",
       "15:50     3\n",
       "06:00     3\n",
       "12:45     3\n",
       "16:15     3\n",
       "15:20     3\n",
       "11:40     3\n",
       "13:15     3\n",
       "08:15     3\n",
       "20:00     3\n",
       "16:45     2\n",
       "16:10     2\n",
       "12:10     2\n",
       "14:10     2\n",
       "13:50     2\n",
       "16:35     2\n",
       "10.00     2\n",
       "16:40     2\n",
       "04:00     2\n",
       "13:20     2\n",
       "09:15     2\n",
       "07:40     2\n",
       "10:20     2\n",
       "9:300     2\n",
       "15:25     2\n",
       "14:20     2\n",
       "12:50     2\n",
       "08:45     2\n",
       "8:000     2\n",
       "13:10     2\n",
       "17:20     1\n",
       "10:25     1\n",
       "21:00     1\n",
       "06:20     1\n",
       "14:11     1\n",
       "8:300     1\n",
       "10:58     1\n",
       "09:50     1\n",
       "14:39     1\n",
       "90000     1\n",
       "?0000     1\n",
       "11000     1\n",
       "10:05     1\n",
       "09:24     1\n",
       "15:15     1\n",
       "12:06     1\n",
       "Avant     1\n",
       "13000     1\n",
       "02:08     1\n",
       "12:20     1\n",
       "10:34     1\n",
       "15:26     1\n",
       "05:00     1\n",
       "14:05     1\n",
       "07:30     1\n",
       "10:50     1\n",
       "09:25     1\n",
       "11:55     1\n",
       "15:10     1\n",
       "10:10     1\n",
       "01:00     1\n",
       "16:20     1\n",
       "11:25     1\n",
       "00:15     1\n",
       "17:50     1\n",
       "16:50     1\n",
       "06:30     1\n",
       "15:40     1\n",
       "11:07     1\n",
       "22:00     1\n",
       "10:39     1\n",
       "09:06     1\n",
       "11.00     1\n",
       "Incon     1\n",
       "9:000     1\n",
       "05:15     1\n",
       "07:20     1\n",
       "11:05     1\n",
       "10:40     1\n",
       "04:30     1\n",
       "12:14     1\n",
       "17:15     1\n",
       "Début     1\n",
       "17:45     1\n",
       "11:13     1\n",
       "05:40     1\n",
       "14:50     1\n",
       "6:000     1\n",
       "12:40     1\n",
       "18:01     1\n",
       "14:à0     1\n",
       "13:05     1\n",
       "08:50     1\n",
       "14:43     1\n",
       "13:35     1\n",
       "09:45     1\n",
       "14:52     1\n",
       "17:05     1\n",
       "11:32     1\n",
       "03:00     1\n",
       "00:00     1\n",
       "18:40     1\n",
       "18:30     1\n",
       "Name: hour, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking values after all transformations to see if more changes are needed\n",
    "df_aval.hour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last changes for times still not fitting the unified version\n",
    "df_aval['hour'].replace('000', ':00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace(['9::00', '9:000'], '09:00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace(['8::00', '8:000'], '08:00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace('14:à0', '14:00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace('9:300', '09:00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace('6::00', '06:00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace('8:300', '08:30', inplace=True, regex=True)\n",
    "df_aval['hour'].replace('.00', ':00', inplace=True, regex=True)\n",
    "df_aval['hour'].replace(['Début', 'Avant', 'Incon'], np.nan, inplace=True, regex=True)\n",
    "df_aval['hour'].replace('\\?:000', np.nan, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12:00    49\n",
       "11:00    47\n",
       "14:00    38\n",
       "15:00    33\n",
       "13:00    31\n",
       "12:30    31\n",
       "10:30    26\n",
       "13:30    26\n",
       "11:30    25\n",
       "16:00    24\n",
       "10:00    22\n",
       "09:00    19\n",
       "15:30    14\n",
       "17:30    12\n",
       "08:00    12\n",
       "14:30    12\n",
       "08:30    10\n",
       "17:00     9\n",
       "11:45     8\n",
       "16:30     7\n",
       "18:00     7\n",
       "10:15     7\n",
       "14:45     6\n",
       "15:45     5\n",
       "14:15     5\n",
       "09:30     5\n",
       "11:15     5\n",
       "10:45     4\n",
       "14:40     4\n",
       "06:00     4\n",
       "11:10     4\n",
       "12:15     4\n",
       "13:45     4\n",
       "14:25     4\n",
       "11:40     3\n",
       "13:15     3\n",
       "08:15     3\n",
       "12:45     3\n",
       "20:00     3\n",
       "16:15     3\n",
       "15:50     3\n",
       "19:00     3\n",
       "13:40     3\n",
       "15:20     3\n",
       "09:15     2\n",
       "13:50     2\n",
       "16:40     2\n",
       "12:50     2\n",
       "14:10     2\n",
       "13:10     2\n",
       "08:45     2\n",
       "10:20     2\n",
       "12:10     2\n",
       "04:00     2\n",
       "14:20     2\n",
       "16:10     2\n",
       "13:20     2\n",
       "16:45     2\n",
       "15:25     2\n",
       "07:40     2\n",
       "16:35     2\n",
       "09:24     1\n",
       "05:15     1\n",
       "02:08     1\n",
       "12:20     1\n",
       "10:25     1\n",
       "06:20     1\n",
       "10:34     1\n",
       "15:15     1\n",
       "14:39     1\n",
       "16:20     1\n",
       "01:00     1\n",
       "05:00     1\n",
       "14:05     1\n",
       "12:06     1\n",
       "17:20     1\n",
       "07:30     1\n",
       "11:25     1\n",
       "09:50     1\n",
       "09:25     1\n",
       "11:55     1\n",
       "15:10     1\n",
       "14:11     1\n",
       "18:30     1\n",
       "18:01     1\n",
       "12:40     1\n",
       "05:40     1\n",
       "00:00     1\n",
       "10:39     1\n",
       "11:32     1\n",
       "14:52     1\n",
       "09:45     1\n",
       "08:50     1\n",
       "17:50     1\n",
       "13:05     1\n",
       "16:50     1\n",
       "00:15     1\n",
       "10:05     1\n",
       "21:00     1\n",
       "10:10     1\n",
       "10:50     1\n",
       "15:26     1\n",
       "17:45     1\n",
       "11:07     1\n",
       "22:00     1\n",
       "03:00     1\n",
       "14:43     1\n",
       "13:35     1\n",
       "17:05     1\n",
       "18:40     1\n",
       "14:50     1\n",
       "11:13     1\n",
       "15:40     1\n",
       "11:05     1\n",
       "10:40     1\n",
       "04:30     1\n",
       "12:14     1\n",
       "17:15     1\n",
       "10:58     1\n",
       "07:20     1\n",
       "06:30     1\n",
       "09:06     1\n",
       "Name: hour, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying all hours are written in same manner\n",
    "df_aval.hour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new variable only for capturing hour\n",
    "df_aval[\"only_hour\"] = df_aval.hour.str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3 - MARQUE       464\n",
       "Inconnu          352\n",
       "2 - LIMITE       190\n",
       "4 - FORT         113\n",
       "1 - FAIBLE        33\n",
       "5 - TRES FORT     15\n",
       "Name: risque_mf, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing distribution of values\n",
    "df_aval.risque_mf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data type of the variable from string to int\n",
    "df_aval.risque_mf = df_aval.risque_mf.str[0:1]\n",
    "df_aval.risque_mf.replace('I', np.nan, inplace=True, regex=True)\n",
    "df_aval.risque_mf = (df_aval.risque_mf.fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data type of the variable from string to int\n",
    "df_aval.only_hour = (df_aval.only_hour.fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167 entries, 0 to 1166\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                Non-Null Count  Dtype         \n",
      "---  ------                                --------------  -----         \n",
      " 0   massif                                1167 non-null   object        \n",
      " 1   mountain/area                         1122 non-null   object        \n",
      " 2   plan_of_trip                          904 non-null    object        \n",
      " 3   orientation                           1167 non-null   object        \n",
      " 4   date                                  1167 non-null   object        \n",
      " 5   year                                  1167 non-null   int64         \n",
      " 6   month                                 1167 non-null   int64         \n",
      " 7   day                                   1167 non-null   int64         \n",
      " 8   date_format                           1167 non-null   datetime64[ns]\n",
      " 9   hour                                  648 non-null    object        \n",
      " 10  description                           1164 non-null   object        \n",
      " 11  remote_avalanche_triggering           1167 non-null   bool          \n",
      " 12  distance_of_remote_trigger            1167 non-null   int64         \n",
      " 13  characteristics                       401 non-null    object        \n",
      " 14  elevation_gain                        1167 non-null   int64         \n",
      " 15  main_cause_of_avalanche               617 non-null    object        \n",
      " 16  secondary_cause_of_avalanche          159 non-null    object        \n",
      " 17  altitude_of_depart                    1167 non-null   int64         \n",
      " 18  thickness_of_avalanche_breakdown      1167 non-null   int64         \n",
      " 19  max_thickness_of_avalanche_breakdown  1167 non-null   int64         \n",
      " 20  length_of_avalanche_breakdown         1167 non-null   int64         \n",
      " 21  main_snowflow                         528 non-null    object        \n",
      " 22  altitude_of_arrival                   1167 non-null   int64         \n",
      " 23  snow_quality                          421 non-null    object        \n",
      " 24  risque_mf                             1167 non-null   int32         \n",
      " 25  only_hour                             1167 non-null   int32         \n",
      "dtypes: bool(1), datetime64[ns](1), int32(2), int64(10), object(12)\n",
      "memory usage: 220.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# last check of all variables and its data types\n",
    "df_aval.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving cleaned dataset\n",
    "avalanches_for_t = df_aval.to_csv(r'.\\\\avalanches_for_t.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Haute Maurienne                         210\n",
       "Vanoise                                 148\n",
       "Haute Tarentaise                        115\n",
       "Maurienne                                81\n",
       "Mont Blanc                               65\n",
       "Aravis                                   57\n",
       "Queyras                                  50\n",
       "Belledonne                               45\n",
       "Oisans                                   45\n",
       "Beaufortain                              43\n",
       "Lauzière                                 42\n",
       "Ecrins                                   33\n",
       "Mont Thabor                              31\n",
       "Cerces                                   21\n",
       "Grandes Rousses                          18\n",
       "Dévoluy                                  15\n",
       "Chartreuse                               15\n",
       "Briançonnais                             14\n",
       "Taillefer                                14\n",
       "Mercantour                               13\n",
       "Ubaye - Parpaillon                       12\n",
       "Aiguilles Rouges                         11\n",
       "Chablais                                 11\n",
       "Vercors                                  10\n",
       "Bauges                                    8\n",
       "Ubaye                                     8\n",
       "Parpaillon                                7\n",
       "Matheysine                                5\n",
       "Embrunais                                 5\n",
       "Champsaur                                 4\n",
       "Chaberton                                 3\n",
       "Guillestrois                              2\n",
       "Haut Giffre                               2\n",
       "Valbonnais                                1\n",
       "Pelvoux                                   1\n",
       "Aiguilles de l'Argentiere/ Sept Laux      1\n",
       "Fiz                                       1\n",
       "Name: massif, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aval.massif.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
